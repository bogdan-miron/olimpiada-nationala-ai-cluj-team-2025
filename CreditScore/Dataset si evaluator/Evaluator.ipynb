{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a688b3e8-04ab-45c3-a9ad-8d89176320ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "def evaluate_candidate_output(ground_truth_path:str, \n",
    "                              candidate_name: str, \n",
    "                              candidate_output_path: str) -> Tuple[float, List]:\n",
    "    detailed_results = [] \n",
    "    \n",
    "    # Load the output_1 file and the output_2 file\n",
    "    output_1 = pd.read_csv(os.path.join(candidate_output_path, 'output_1.csv'))\n",
    "    output_2 = pd.read_csv(os.path.join(candidate_output_path, 'output_2.csv'))\n",
    "\n",
    "    #### Evaluate the output_1 file ####\n",
    "    print(f\"Evaluating candidate: {candidate_name}\")\n",
    "\n",
    "    # Check if the output_1 has the expected columns\n",
    "    is_output_1_correct = output_1.columns.tolist() == [\"Samples\",\"Avg_Debt\",\"Unique_Months\",\"SSN_Count\"]\n",
    "    score_output_1 = 0\n",
    "    if is_output_1_correct:\n",
    "        print(\"output_1 columns are correct\")\n",
    "        if output_1[\"Samples\"].iloc[0] == 44207:\n",
    "            detailed_results.append(10)\n",
    "            score_output_1 += detailed_results[-1]\n",
    "            print(\"Samples column is correct\")\n",
    "\n",
    "        if output_1[\"Avg_Debt\"].iloc[0] == 4106:\n",
    "            detailed_results.append(10)\n",
    "            score_output_1 += detailed_results[-1]\n",
    "            print(\"Average Debt column is correct\")\n",
    "\n",
    "        if output_1[\"Unique_Months\"].iloc[0] == 8:\n",
    "            detailed_results.append(10)\n",
    "            score_output_1 += detailed_results[-1]\n",
    "            print(\"Average Owners column is correct\")\n",
    "\n",
    "        if output_1[\"SSN_Count\"].iloc[0] == 109:\n",
    "            detailed_results.append(10)\n",
    "            score_output_1 += detailed_results[-1]\n",
    "            print(\"Unique Genres column is correct\")\n",
    "    else:\n",
    "            detailed_results.extend([0]*4)\n",
    "\n",
    "    ### Evaluate the output_2 file ####\n",
    "    score_output_2 = 0\n",
    "    is_output_2_correct = output_2.columns.tolist() == [\"ID\", \"Credit_Score\"]\n",
    "    if is_output_2_correct:\n",
    "        print(\"output_2 columns are correct\")\n",
    "\n",
    "        # Load the dataset_eval_t dataset that contains the column Price then compare it with the output_2 price column using MAE metric\n",
    "        # Do the mae for each row then sum all the mae and divide it by the number of rows\n",
    "        dataset_eval_t = pd.read_csv(os.path.join(ground_truth_path, 'dataset_eval_t.csv'))\n",
    "        if is_output_2_correct:\n",
    "            # mae = (dataset_eval_t[\"Price\"] - output_2[\"Price\"]).abs().sum() / len(dataset_eval_t)\n",
    "            # print(\"MAE: \", mae)\n",
    "            matching_rows = (output_2['Credit_Score'] == dataset_eval_t[\"Credit_Score\"]).sum()\n",
    "            acc = ( matching_rows / len(dataset_eval_t) ) * 100\n",
    "            # acc = int(acc)\n",
    "            print(f'Accuracy: {acc}%')\n",
    "            print(f'Matching rows: {matching_rows}')\n",
    "    \n",
    "            # Assign scores based on MAE value\n",
    "            import bisect\n",
    "            ranges = [50, 60, 70, 80, 90]\n",
    "            scores = [10, 20, 50, 60, 70]\n",
    "    \n",
    "            index = bisect.bisect_left(ranges, acc)\n",
    "            if index < len(scores):\n",
    "                score_output_2 += scores[index]\n",
    "\n",
    "            detailed_results.append(score_output_2)\n",
    "    \n",
    "            print(\"Took the score: \", score_output_2)\n",
    "        else:\n",
    "            detailed_resuts.append(0)\n",
    "\n",
    "\n",
    "    # Calculate the total score\n",
    "    total_score = score_output_1 + score_output_2\n",
    "    print(\"Total score: \", total_score)\n",
    "\n",
    "    return total_score, detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5321dc21-1229-4aaf-b466-c07580198986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Candidat_incepator']\n",
      "Evaluating candidate: Candidat_incepator\n",
      "output_1 columns are correct\n",
      "Samples column is correct\n",
      "Average Debt column is correct\n",
      "Average Owners column is correct\n",
      "Unique Genres column is correct\n",
      "output_2 columns are correct\n",
      "Accuracy: 57.10892432982694%\n",
      "Matching rows: 5049\n",
      "Took the score:  20\n",
      "Total score:  60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Detailed</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candidat_incepator</td>\n",
       "      <td>[10, 10, 10, 10, 20]</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name              Detailed  Total\n",
       "0  Candidat_incepator  [10, 10, 10, 10, 20]     60"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take all candidates and evaluate them. Create a final csv with outputs \n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Open the outputs from candidates\n",
    "candidates_path = Path(\"../Solutii\")\n",
    "folder_candidati = [f.name for f in candidates_path.iterdir() if f.is_dir()]\n",
    "print(folder_candidati)\n",
    "\n",
    "# Open each candidates and run the evaluator\n",
    "candidate_results = []\n",
    "for candidate_name in folder_candidati:\n",
    "    if candidate_name[0] == '.':\n",
    "        continue \n",
    "        \n",
    "    candidat_path = candidates_path / candidate_name\n",
    "    \n",
    "    relative_path = str(Path(candidat_path))\n",
    "    total_score, detailed_results = evaluate_candidate_output(ground_truth_path=\"Dataset\",\n",
    "                              candidate_name=candidate_name,\n",
    "                              candidate_output_path=relative_path)\n",
    "\n",
    "    candidate_results.append({'Name' : candidate_name, 'Detailed': detailed_results, 'Total' : total_score})\n",
    "\n",
    "df = pd.DataFrame(candidate_results)\n",
    "df = df.sort_values(by=\"Total\", ascending=False)  # Sort in descending order (highest score first)\n",
    "df.to_csv(candidates_path/ \"rezultate.csv\", index=False)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da58385-1fe0-49ff-b6e4-b98d8875683d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
